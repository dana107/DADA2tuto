---
title: "R Notebook"
output: github_document
---
####lire dada2####
```{r}
library(dada2)
```
####installation de Rcpp pour pouvoir continuer avec DADA2
```{r}
install.packages("Rcpp")
```
```{r}
library(Rcpp)
```
```{r}
library(dada2)
```
####getting ready :chnager le directory vers celui contenant les fichiers fastq unziper pour pouvoir travailler (on a choisi le chemin des files unzipé)
```{r}
path <- "/home/rstudio/tutorial/DADA2tuto/MiSeq_SOP"
list.files(path)
```
####en dessus ce sont les noms des fichiers que je travaillerais avec
```{r}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```
```{r}
sample.names
```
#####ce sont les noms des echantillons###
#####Inspect read quality profiles#####
####voire le profile de qualité des plots####
```{r}
plotQualityProfile(fnFs[1:2])
```
```{r}
plotQualityProfile(fnRs[1:2])
```
####filter and trim####
####attribuer les noms de fichiers aux fichiers filtrés####
```{r}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```
####en dessus on a filtrer les files, on a enlever toutes les sequences de mauvaise qualité (le bruit)
####en dessous pour creer une nouvelle data dans lequelle il y a les sequences de bonnes qualité
```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```
#####learn the error rates#####
####il vas prendre en compte les frequence d'erreur dans les sequences pour dessider si c'est une vraie séquence si elle est tres frequente ou si elle est une erreur si elle n'est pas asser frequente
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```
####visualiser les taux d'erreur estimés
```{r}
plotErrors(errF, nominalQ=TRUE)
```
```{r}
plotErrors(errR, nominalQ=TRUE)
```
####sample inference####
####appliquer l'algorithme d'inférence d'échantillon de base aux données de séquence filtrées et découpées####
#### pour sample 1 explication :pour forward, sur 7113 seq retrouver;il y a 1979 considerer comme sequence uniques####
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```
####pour l'autre maintenant####
#### pour sample 1 explication :pour reverse, sur 7113 seq retrouver;il y a 1660 considerer comme sequence uniques####
```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
####Inspecting the returned dada-class object####
####description du 1 ere fichier dans dadaFs
```{r}
dadaFs[[1]]
```
####merge paired reads####
####le but est de rassembler les seauences, par exemple au lieu d'avoir 2 fichier pour sample one : un pour forword et un pour reverse, on fait un merge pour avoir un seul fichier pour sample one contenant forword et reverse####
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
####Construct sequence table####
#### dans le tableau il y a 
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
####inspecter la distribution de la longeur de la séquence
```{r}
table(nchar(getSequences(seqtab)))
```
####enlever les chimères (les fusions des sequences F et R)####
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab)
```
####track reads through the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
####Assign taxonomy####
```{r}
taxa <- assignTaxonomy(seqtab.nochim,"/home/rstudio/tutorial/DADA2tuto/tax/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
```









